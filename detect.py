# YOLOv5 ğŸš€ by Ultralytics, AGPL-3.0 license
"""
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources: # verilerin nereden aldÄ±ÄŸÄ±nÄ± belirtmektedir
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam  # bu komut detect.py dosyasÄ±nda ki nesne tanÄ±mlama modÃ¼lÃ¼nÃ¼n Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

# bu kdolamalar Ã§alÄ±ÅŸacak olan yolov5 modÃ¼lÃ¼nÃ¼n Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ± ve kapsadÄ±ÄŸÄ± dosya veya baÄŸlamtÄ±larÄ±n modellerini temsil ediyor.

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle
"""
# Bu komutla, YOLOv5 modelinin farklÄ± formatlarda dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ versiyonlarÄ±nÄ± kullanarak nesne ayrÄ±ntÄ±larÄ±nÄ± gerÃ§ekleÅŸtirmeye olanak tanÄ±r

import argparse
import os
import platform
import sys
from pathlib import Path

import torch
# 31-35 gerekli olan kÃ¼tÃ¼phaneleri iÃ§e aaktarÄ±r

FILE = Path(__file__).resolve()  # Bu satÄ±r, mevcut dosyanÄ±n yolunu alÄ±r ve Ã§Ã¶zÃ¼mler.
ROOT = FILE.parents[0]  # YOLOv5 kÃ¶k dizini. DosyanÄ±n Ã¼st dizinine eriÅŸir.
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # ROOT'u PATH'e ekler.
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # KÃ¶kÃ¼ mevcut Ã§alÄ±ÅŸma dizinine gÃ¶re gÃ¶receli hale getirir.

# YOLOv5 kodu iÃ§eriÄŸi
from ultralytics.utils.plotting import Annotator, colors, save_one_box  # Ultralytics kÃ¼tÃ¼phanesinden gerekli modÃ¼lleri alÄ±r.

from models.common import DetectMultiBackend  # Ortak modellerden 'DetectMultiBackend' modÃ¼lÃ¼nÃ¼ alÄ±r.
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams  # Veri yÃ¼kleyici modÃ¼lleri.
from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,
                           increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)
# Genel yardÄ±mcÄ± iÅŸlevlerin olduÄŸu modÃ¼lÃ¼ iÃ§eriye dahil eder.
from utils.torch_utils import select_device, smart_inference_mode
# PyTorch ile ilgili yardÄ±mcÄ± iÅŸlevleri iÃ§eriye dahil eder.



@smart_inference_mode() #bir sÄ±nÄ±f iÃ§indeki bir metodu veya iÅŸlevi dekore etmek iÃ§in kullanÄ±lÄ±r
def run( #run adÄ±nda bir sÄ±nÄ±f tanÄ±mlanÄ±r
    weights=ROOT / 'yolov5s.pt',  # YOLOv5 modelinin aÄŸÄ±rlÄ±klarÄ±nÄ±n dosya yolu veya triton URL
    source=ROOT / 'data/images',  # AlgÄ±lama yapÄ±lacak olan dosya, dizin, URL, glob, ekran gÃ¶rÃ¼ntÃ¼sÃ¼ veya web kamerasÄ± kaynaÄŸÄ±
    data=ROOT / 'data/coco128.yaml',  # Veri seti yapÄ±landÄ±rma dosyasÄ±nÄ±n (dataset.yaml) yolu
    imgsz=(640, 640),  # Ã‡Ä±karÄ±m boyutlarÄ± (yÃ¼kseklik, geniÅŸlik) - gÃ¶rÃ¼ntÃ¼ boyutu
    conf_thres=0.25,  # GÃ¼ven eÅŸiÄŸi (confidence threshold)
    iou_thres=0.45,  # NMS (Non-Maximum Suppression) IOU eÅŸiÄŸi
    max_det=1000,  # Her bir gÃ¶rÃ¼ntÃ¼deki maksimum tespit sayÄ±sÄ±
    device='',  # CUDA cihazÄ±, Ã¶rneÄŸin 0 veya 0,1,2,3 veya cpu
    view_img=False,  # SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leme
    save_txt=False,  # *.txt olarak sonuÃ§larÄ± kaydetme
    save_conf=False,  # --save-txt etiketlerinde gÃ¼venleri kaydetme
    save_crop=False,  # KesilmiÅŸ tahmin kutularÄ±nÄ± kaydetme
    nosave=False,  # GÃ¶rÃ¼ntÃ¼leri/videolarÄ± kaydetmeme
    classes=None,  # SÄ±nÄ±fa gÃ¶re filtreleme: --class 0 veya --class 0 2 3
    agnostic_nms=False,  # SÄ±nÄ±f-agnostic NMS
    augment=False,  # ArtÄ±rÄ±lmÄ±ÅŸ Ã§Ä±karÄ±m
    visualize=False,  # Ã–zellikleri gÃ¶rselleÅŸtirme
    update=False,  # TÃ¼m modelleri gÃ¼ncelleme
    project=ROOT / 'runs/detect',  # SonuÃ§larÄ± projeye/adÄ± kaydetme
    name='exp',  # SonuÃ§larÄ± proje/ad ile kaydetme
    exist_ok=False,  # Var olan proje/ad geÃ§erli, arttÄ±rmama
    line_thickness=3,  # SÄ±nÄ±rlayÄ±cÄ± kutu kalÄ±nlÄ±ÄŸÄ± (piksel)
    hide_labels=False,  # Etiketleri gizleme
    hide_conf=False,  # GÃ¼venleri gizleme
    half=False,  # FP16 yarÄ±-kesinlikli Ã§Ä±karÄ±m kullanma
    dnn=False,  # ONNX Ã§Ä±karÄ±mÄ± iÃ§in OpenCV DNN kullanma
    vid_stride=1,  # Video kare hÄ±zÄ± adÄ±mÄ±
):
    source = str(source)  # KaynaÄŸÄ± bir dizeye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    save_img = not nosave and not source.endswith('.txt')  # Ã‡Ä±karÄ±m gÃ¶rÃ¼ntÃ¼lerini kaydetme koÅŸulu
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)  # Dosya uzantÄ±sÄ±nÄ± kontrol eder
    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))  # KaynaÄŸÄ±n URL olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    webcam = source.isnumeric() or source.endswith('.streams') or (is_url and not is_file)  # Web kamerasÄ±ndan veya akÄ±ÅŸlardan gÃ¶rÃ¼ntÃ¼ alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±nÄ± kontrol eder
    screenshot = source.lower().startswith('screen')  # Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±nÄ± kontrol eder

    if is_url and is_file:
        source = check_file(source)  # Ä°ndirme iÅŸlemi

    # Dizinler
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # Ã‡alÄ±ÅŸmayÄ± artÄ±rÄ±r
    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # Dizin oluÅŸturur

    # Modeli YÃ¼kleme
    device = select_device(device)  # CihazÄ± seÃ§er
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)  # Modeli yÃ¼kler
    stride, names, pt = model.stride, model.names, model.pt  # AdÄ±mlama, isimler ve pt (model) bilgilerini alÄ±r
    imgsz = check_img_size(imgsz, s=stride)  # GÃ¶rÃ¼ntÃ¼ boyutunu kontrol eder

    # Veri YÃ¼kleyici
    bs = 1  # Toplu iÅŸ boyutu
    if webcam:
        view_img = check_imshow(warn=True)  # GÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶sterme koÅŸulunu kontrol eder
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)  # AkÄ±ÅŸlarÄ± yÃ¼kler
        bs = len(dataset)
    elif screenshot:
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)  # Ekran gÃ¶rÃ¼ntÃ¼lerini yÃ¼kler
    else:
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)  # GÃ¶rÃ¼ntÃ¼leri yÃ¼kler
    vid_path, vid_writer = [None] * bs, [None] * bs  # Video yolu ve yazÄ±cÄ±larÄ±nÄ± belirler


    # Ã‡Ä±karÄ±m yapma
    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # Modeli hazÄ±rlama

    seen, windows, dt = 0, [], (Profile(), Profile(), Profile())  # DeÄŸiÅŸkenlerin baÅŸlangÄ±Ã§ deÄŸerleri

    for path, im, im0s, vid_cap, s in dataset:  # Veri kÃ¼mesindeki her bir veri iÃ§in dÃ¶ngÃ¼
        with dt[0]:  # Zaman Ã¶lÃ§Ã¼mÃ¼ iÃ§in
            im = torch.from_numpy(im).to(model.device)  # GÃ¶rÃ¼ntÃ¼yÃ¼ tensora dÃ¶nÃ¼ÅŸtÃ¼rme ve cihaza yÃ¼kleme
            im = im.half() if model.fp16 else im.float()  # Veri tipini ayarlama (fp16 veya float32)
            im /= 255  # 0 - 255 aralÄ±ÄŸÄ±ndaki piksel deÄŸerlerini 0.0 - 1.0 aralÄ±ÄŸÄ±na normalizasyon
            if len(im.shape) == 3:
                im = im[None]  # Tek bir gÃ¶rÃ¼ntÃ¼ iÃ§in boyutu geniÅŸletme (batch dim)

        # Ã‡Ä±karÄ±m iÅŸlemi
        with dt[1]:  # Zaman Ã¶lÃ§Ã¼mÃ¼ iÃ§in
            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False  # GÃ¶rÃ¼ntÃ¼leri kaydetme yolu
            pred = model(im, augment=augment, visualize=visualize)  # Model Ã¼zerinden Ã§Ä±karÄ±m yapma

        # NMS (Non-Maximum Suppression)
        with dt[2]:  # Zaman Ã¶lÃ§Ã¼mÃ¼ iÃ§in
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)  # Ã‡Ä±ktÄ±larÄ± filtreleme (NMS)

        # Tahminleri iÅŸleme
        for i, det in enumerate(pred):  # Her bir gÃ¶rÃ¼ntÃ¼ iÃ§in iÅŸlem yapma
            seen += 1  # GÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±nÄ± artÄ±rma
            if webcam:  # web kamerasÄ±ndan geliyorsa (batch_size >= 1)
                p, im0, frame = path[i], im0s[i].copy(), dataset.count  # Yolu, gÃ¶rÃ¼ntÃ¼yÃ¼ ve kare sayÄ±sÄ±nÄ± alÄ±r
                s += f'{i}: '  # SayaÃ§ gÃ¼ncelleme
            else:
                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)  # Yolu, gÃ¶rÃ¼ntÃ¼yÃ¼ ve kare sayÄ±sÄ±nÄ± alÄ±r

        p = Path(p)  # Yolu 'Path' nesnesine dÃ¶nÃ¼ÅŸtÃ¼rme
        save_path = str(save_dir / p.name)  # KayÄ±t edilecek gÃ¶rÃ¼ntÃ¼ yolunu oluÅŸturma (im.jpg)
        txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # Etiket dosyasÄ±nÄ±n yolu (im.txt)
        s += '%gx%g ' % im.shape[2:]  # YazdÄ±rÄ±lacak metni oluÅŸturma (gÃ¶rÃ¼ntÃ¼ boyutlarÄ±)

        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # Normalizasyon faktÃ¶rÃ¼ (whwh)
        imc = im0.copy() if save_crop else im0  # save_crop iÃ§in gÃ¶rÃ¼ntÃ¼ kopyasÄ± oluÅŸturma

        annotator = Annotator(im0, line_width=line_thickness, example=str(names))  # Etiketleme iÃ§in annotator oluÅŸturma

        if len(det):
            det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()  # KutularÄ± img_size boyutundan im0 boyutuna yeniden Ã¶lÃ§eklendirme

            for c in det[:, 5].unique():  # Her sÄ±nÄ±f iÃ§in tekrar sayÄ±sÄ±nÄ± ve sÄ±nÄ±f adÄ±nÄ± metne ekler
                n = (det[:, 5] == c).sum()  # SÄ±nÄ±f bazÄ±nda algÄ±lama sayÄ±sÄ±
                s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # Metne ekleme

            for *xyxy, conf, cls in reversed(det):  # Her bir algÄ±lama iÃ§in iÅŸlem yapma
                if save_txt:  # Dosyaya yazma
                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # Normalized xywh
                    line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # Etiket formatÄ±
                    with open(f'{txt_path}.txt', 'a') as f:
                        f.write(('%g ' * len(line)).rstrip() % line + '\n')  # Etiketleri dosyaya yazma

                if save_img or save_crop or view_img:  # bbox'Ä± gÃ¶rÃ¼ntÃ¼ye ekleme
                    c = int(cls)  # SÄ±nÄ±fÄ±n integer deÄŸeri
                    label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')  # Etiket
                    annotator.box_label(xyxy, label, color=colors(c, True))  # bbox'Ä± gÃ¶rÃ¼ntÃ¼ye ekleme
                    if save_crop:  # bbox'Ä± kaydetme
                        save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)

        # SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼ye ekleme ve gÃ¶rÃ¼ntÃ¼leme
        im0 = annotator.result()
        if view_img:  # GÃ¶rÃ¼ntÃ¼yÃ¼ gÃ¶sterme
            if platform.system() == 'Linux' and p not in windows:
                windows.append(p)
                cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # Pencere boyutunu ayarlama (Linux)
                cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
            cv2.imshow(str(p), im0)
            cv2.waitKey(1)  # 1 milisaniyelik bekleme sÃ¼resi

        # SonuÃ§larÄ± kaydetme (algÄ±lamalÄ± gÃ¶rÃ¼ntÃ¼)
        if save_img:  
            if dataset.mode == 'image':
                cv2.imwrite(save_path, im0)  # GÃ¶rÃ¼ntÃ¼yÃ¼ kaydetme
            else:  # 'video' veya 'stream'
                if vid_path[i] != save_path:  # Yeni bir video
                    vid_path[i] = save_path
                    if isinstance(vid_writer[i], cv2.VideoWriter):
                        vid_writer[i].release()  # Ã–nceki video yazarÄ±nÄ± serbest bÄ±rakma
                    if vid_cap:  # video
                        fps = vid_cap.get(cv2.CAP_PROP_FPS)
                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    else:  # stream
                        fps, w, h = 30, im0.shape[1], im0.shape[0]
                    save_path = str(Path(save_path).with_suffix('.mp4'))  # SonuÃ§ videosuna *.mp4 uzantÄ±sÄ± verme
                    vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))  # Video yazarÄ± oluÅŸturma
                vid_writer[i].write(im0)  # Videoya gÃ¶rÃ¼ntÃ¼yÃ¼ yazma

        # ZamanÄ± yazdÄ±rma (yalnÄ±zca Ã§Ä±karÄ±m sÃ¼resi)
        LOGGER.info(f"{s}{'' if len(det) else '(tespit yok), '}{dt[1].dt * 1E3:.1f}ms")

        # SonuÃ§larÄ± yazdÄ±rma
        t = tuple(x.t / seen * 1E3 for x in dt)  # her bir gÃ¶rÃ¼ntÃ¼ iÃ§in hÄ±zlar
        LOGGER.info(f'Speed: %.1fms Ã¶n iÅŸleme, %.1fms Ã§Ä±karÄ±m, %.1fms NMS, her bir gÃ¶rÃ¼ntÃ¼de (boyut: {(1, 3, *imgsz)})' % t)

        # SonuÃ§larÄ± kaydetme
        if save_txt or save_img:
            s = f"\n{len(list(save_dir.glob('labels/*.txt')))} etiket {save_dir / 'labels'} klasÃ¶rÃ¼ne kaydedildi" if save_txt else ''
            LOGGER.info(f"SonuÃ§lar {colorstr('bold', save_dir)} klasÃ¶rÃ¼ne kaydedildi{s}")

        # Model gÃ¼ncellemesi
        if update:
            strip_optimizer(weights[0])  # modeli gÃ¼ncelle (SourceChangeWarning'u dÃ¼zeltmek iÃ§in)


def parse_opt():
    # ArgÃ¼manlarÄ± analiz etmek iÃ§in bir argÃ¼man analizcisi oluÅŸturma
    parser = argparse.ArgumentParser()

    # ArgÃ¼manlarÄ± tanÄ±mlama
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'yolov5s.pt', help='model path or triton URL')
    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob/screen/0(webcam)')
    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='(optional) dataset.yaml path')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='show results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')
    opt = parser.parse_args()  # ArgÃ¼manlarÄ± ayrÄ±ÅŸtÄ±rma
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # imgsz boyutunu geniÅŸletme
    print_args(vars(opt))  # ArgÃ¼manlarÄ± yazdÄ±rma
    return opt  # ArgÃ¼manlarÄ± dÃ¶ndÃ¼rme


def main(opt):
    check_requirements(ROOT / 'requirements.txt', exclude=('tensorboard', 'thop'))  # Gerekli kÃ¼tÃ¼phaneleri kontrol etme
    run(**vars(opt))  # Ã‡Ä±karÄ±m iÅŸlemini Ã§alÄ±ÅŸtÄ±rma


if __name__ == '__main__':
    opt = parse_opt()  # ArgÃ¼manlarÄ± ayrÄ±ÅŸtÄ±rma
    main(opt)  # Ana iÅŸlevi Ã§aÄŸÄ±rma
